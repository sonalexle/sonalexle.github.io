---
permalink: /
title: "About me"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

Hei! I'm a student at [Aalto University](https://www.aalto.fi/en), and I'm pursuing a Bachelor's degree in Data Science, with a minor in Statistics.
I expect to graduate in summer 2022, probably in June.
I will undertake Master's studies in fall 2022 also at Aalto (I'm enrolled in a continuous BSc + MSc program) or elsewhere.
I'm also working as a research assistant for the Aalto Probabilistic Machine Learning group.

My undergraduate studies cover the foundations of data science: computer science, math, and statistics.
In addition, through university courses, projects, and internships, I have obtained a solid foundation of machine learning (ML),
grounded in math and computer science.

In general, I am interested in machine learning engineering, probabilistic machine learning, deep learning, and causality and its connections with machine learning.

<!-- # Interests

## Research interests

My research interests include causality (causal inference and causal discovery), deep learning (DL), and probabilistic machine learning (PML).

With causal analysis, one can transition from pattern recognition done by typical ML methods to interventions and counterfactual reasoning, a desirable property of intelligent systems. I mainly work with causal inference assumptions and treatment effect estimation methods, such as double machine learning, doubly robust estimators, and instrumental variables. One could also estimate treatment effects with arbitrary ML models. However, to do so, one needs to be informed of which explanatory variables to include. This information is usually encoded as a directed acyclic graph (DAG), which is one type of probabilistic graphical models (PGMs).

Regarding PML, I'm interested in latent variable modeling, PGMs, Bayesian inference, and variational inference. I believe that probabilistic modeling could make ML more transparent by providing outputs augmented with uncertainty measures such as credible intervals (instead of just a number like, e.g., random forests), which would be more informative to users and decision-makers.

When it comes to DL, I like to study various models for different applications, such as natural language processing or computer vision.
I'm familiar with most common models and methods: CNN, RNN (LSTM, GRU), transformers, GAN, and VAE.
I'm not so interested in coming up with new modules such as attention, but rather I like to discover unexpected ways to successfully integrate different building blocks and build a good DL model.

At the intersection of causality, DL, and PML, I'm investigating how to encode causal relationships as inductive biases for ML models while learning how to improve the performance of causal estimators with complex ML methods such as neural networks. That is, I'd like to know how ML could help causality and vice versa. However, both causal inference and ML methods typically lack uncertainty quantification, and this is where the probabilistic modeling framework could help.

## Machine learning engineering

Today's ML research is still disconnected from the industry, whose services could affect millions of people. Whereas ML research typically focuses on inventing models with high accuracies, real-world software services need continuous deployment and updates reflecting the surrounding environment. This is especially true for ML-based services because the deployed ML model is invalid once the environment differs from data used to train the model. The emerging field of MLOps aims to address this by, e.g., providing tools for integrating ML with a larger service by leveraging best practices from software development and DevOps. As a first step towards becoming an ML engineer and bridge the gap between ML research and industry, I have recently completed a course [project](https://sonalexle.github.io/viral-tweets/) about MLOps and the BERT language model. -->

